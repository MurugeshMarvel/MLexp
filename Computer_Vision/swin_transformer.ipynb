{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import SwinTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    img_size=224, in_chans=1,\n",
    "    patch_size=2, window_size=2, embed_dim=96, depths=(2, 2, 6, 2), num_heads=(3, 6, 12, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinTransformer(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = T.rand((1,1,224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_cfg(\n",
    "        model_cls: Callable,\n",
    "        variant: str,\n",
    "        pretrained: bool,\n",
    "        pretrained_cfg: Optional[Dict] = None,\n",
    "        model_cfg: Optional[Any] = None,\n",
    "        feature_cfg: Optional[Dict] = None,\n",
    "        pretrained_strict: bool = False,\n",
    "        pretrained_filter_fn: Optional[Callable] = None,\n",
    "        pretrained_custom_load: bool = False,\n",
    "        kwargs_filter: Optional[Tuple[str]] = None,\n",
    "        **kwargs):\n",
    "    \"\"\" Build model with specified default_cfg and optional model_cfg\n",
    "    This helper fn aids in the construction of a model including:\n",
    "      * handling default_cfg and associated pretrained weight loading\n",
    "      * passing through optional model_cfg for models with config based arch spec\n",
    "      * features_only model adaptation\n",
    "      * pruning config / model adaptation\n",
    "    Args:\n",
    "        model_cls (nn.Module): model class\n",
    "        variant (str): model variant name\n",
    "        pretrained (bool): load pretrained weights\n",
    "        pretrained_cfg (dict): model's pretrained weight/task config\n",
    "        model_cfg (Optional[Dict]): model's architecture config\n",
    "        feature_cfg (Optional[Dict]: feature extraction adapter config\n",
    "        pretrained_strict (bool): load pretrained weights strictly\n",
    "        pretrained_filter_fn (Optional[Callable]): filter callable for pretrained weights\n",
    "        pretrained_custom_load (bool): use custom load fn, to load numpy or other non PyTorch weights\n",
    "        kwargs_filter (Optional[Tuple]): kwargs to filter before passing to model\n",
    "        **kwargs: model args passed through to model __init__\n",
    "    \"\"\"\n",
    "    pruned = kwargs.pop('pruned', False)\n",
    "    features = False\n",
    "    feature_cfg = feature_cfg or {}\n",
    "\n",
    "    # resolve and update model pretrained config and model kwargs\n",
    "    pretrained_cfg = resolve_pretrained_cfg(variant, pretrained_cfg=pretrained_cfg)\n",
    "    update_pretrained_cfg_and_kwargs(pretrained_cfg, kwargs, kwargs_filter)\n",
    "    pretrained_cfg.setdefault('architecture', variant)\n",
    "\n",
    "    # Setup for feature extraction wrapper done at end of this fn\n",
    "    if kwargs.pop('features_only', False):\n",
    "        features = True\n",
    "        feature_cfg.setdefault('out_indices', (0, 1, 2, 3, 4))\n",
    "        if 'out_indices' in kwargs:\n",
    "            feature_cfg['out_indices'] = kwargs.pop('out_indices')\n",
    "\n",
    "    # Build the model\n",
    "    model = model_cls(**kwargs) if model_cfg is None else model_cls(cfg=model_cfg, **kwargs)\n",
    "    model.pretrained_cfg = pretrained_cfg\n",
    "    model.default_cfg = model.pretrained_cfg  # alias for backwards compat\n",
    "    \n",
    "    if pruned:\n",
    "        model = adapt_model_from_file(model, variant)\n",
    "\n",
    "    # For classification models, check class attr, then kwargs, then default to 1k, otherwise 0 for feats\n",
    "    num_classes_pretrained = 0 if features else getattr(model, 'num_classes', kwargs.get('num_classes', 1000))\n",
    "    if pretrained:\n",
    "        if pretrained_custom_load:\n",
    "            # FIXME improve custom load trigger\n",
    "            load_custom_pretrained(model, pretrained_cfg=pretrained_cfg)\n",
    "        else:\n",
    "            load_pretrained(\n",
    "                model,\n",
    "                pretrained_cfg=pretrained_cfg,\n",
    "                num_classes=num_classes_pretrained,\n",
    "                in_chans=kwargs.get('in_chans', 3),\n",
    "                filter_fn=pretrained_filter_fn,\n",
    "                strict=pretrained_strict)\n",
    "\n",
    "    # Wrap the model in a feature extraction module if enabled\n",
    "    if features:\n",
    "        feature_cls = FeatureListNet\n",
    "        if 'feature_cls' in feature_cfg:\n",
    "            feature_cls = feature_cfg.pop('feature_cls')\n",
    "            if isinstance(feature_cls, str):\n",
    "                feature_cls = feature_cls.lower()\n",
    "                if 'hook' in feature_cls:\n",
    "                    feature_cls = FeatureHookNet\n",
    "                elif feature_cls == 'fx':\n",
    "                    feature_cls = FeatureGraphNet\n",
    "                else:\n",
    "                    assert False, f'Unknown feature class {feature_cls}'\n",
    "        model = feature_cls(model, **feature_cfg)\n",
    "        model.pretrained_cfg = pretrained_cfg_for_features(pretrained_cfg)  # add back default_cfg\n",
    "        model.default_cfg = model.pretrained_cfg  # alias for backwards compat\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
